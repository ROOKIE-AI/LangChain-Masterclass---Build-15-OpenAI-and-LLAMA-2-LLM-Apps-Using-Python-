{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rookiehhh/LangChain-Masterclass---Build-15-OpenAI-and-LLAMA-2-LLM-Apps-Using-Python-/blob/main/S05%20-%20Project%201%20-%20Simple%20Question%20and%20Answer%20App/LLM%20Practical%20Implementation%20using%20Python/LLM%20Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b947c78e",
      "metadata": {
        "id": "b947c78e"
      },
      "source": [
        "<font color='green'>\n",
        "Pip install is the command you use to install Python packages with the help of a tool called Pip package manager.\n",
        "<br><br>Installing LangChain package\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32c225b4",
      "metadata": {
        "id": "32c225b4"
      },
      "source": [
        "## Let's use Proprietary LLM from - OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a0e925c",
      "metadata": {
        "id": "2a0e925c"
      },
      "source": [
        "<font color='green'>\n",
        "Installing Openai package, which includes the classes that we can use to communicate with Openai services\n",
        "<font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5cb5a1a7",
      "metadata": {
        "id": "5cb5a1a7"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet openai==0.28 langchain langchain_community huggingface-hub==0.21.4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f274e9c5",
      "metadata": {
        "id": "f274e9c5"
      },
      "source": [
        "<font color='green'>\n",
        "Imports the Python built-in module called \"os.\"\n",
        "<br>This module provides a way to interact with the operating system, such as accessing environment variables, working with files and directories, executing shell commands, etc\n",
        "<br><br>\n",
        "The environ attribute is a dictionary-like object that contains the environment variables of the current operating system session\n",
        "<br><br>\n",
        "By accessing os.environ, you can retrieve and manipulate environment variables within your Python program. For example, you can retrieve the value of a specific environment variable using the syntax os.environ['VARIABLE_NAME'], where \"VARIABLE_NAME\" is the name of the environment variable you want to access.\n",
        "<font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a4d278e8",
      "metadata": {
        "id": "a4d278e8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY_RAW')\n",
        "openai.base_url = \"https://api.openai.com/v1/chat/completions\""
      ],
      "metadata": {
        "id": "Aw00HL3N4Vr8"
      },
      "id": "Aw00HL3N4Vr8",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5aef06cb",
      "metadata": {
        "id": "5aef06cb"
      },
      "source": [
        "<font color='green'>\n",
        "LangChain has built a Wrapper around OpenAI APIs, using which we can get access to all the services OpenAI provides.\n",
        "<br>\n",
        "The code snippet below imports a specific class called 'OpenAI'(Wrapper around OpenAI large language models) from the 'llms' module of the 'langchain' library.\n",
        "\n",
        "<br>https://python.langchain.com/en/latest/_modules/langchain/llms/openai.html\n",
        "<font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "db64eaa7",
      "metadata": {
        "id": "db64eaa7"
      },
      "outputs": [],
      "source": [
        "#As Langchain team has been working aggresively on improving the tool, we can see a lot of changes happening every weeek,\n",
        "#As a part of it, the below import has been depreciated\n",
        "#from langchain.llms import OpenAI\n",
        "\n",
        "#First we'll need to import the below LangChain - OpenAI integration package and then import it please, if not installed already\n",
        "\n",
        "# !pip install langchain-openai==0.1.0\n",
        "\n",
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a9d124f",
      "metadata": {
        "id": "6a9d124f"
      },
      "source": [
        "<font color='green'>Here we are instantiating a language model object called OpenAI, for our natural language processing tasks.\n",
        "<br><br>\n",
        "The parameter model_name is provided with the value \"text-davinci-003\" which is a specific version or variant of a language model (examples - text-davinci-003, code-davinci-002, gpt-3.5-turbo, text-ada-001 and more).\n",
        "<font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9a3be989",
      "metadata": {
        "id": "9a3be989"
      },
      "outputs": [],
      "source": [
        "# 'text-davinci-003' model is depreciated now, so we are using the openai's reccomended model\n",
        "model_name = \"gpt-3.5-turbo\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(message, model_name='gpt-3.5-turbo'):\n",
        "  response = openai.ChatCompletion.create(\n",
        "    model = model_name,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": message}  # User's complaint passed as content\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "tWebKhib6Wo-"
      },
      "id": "tWebKhib6Wo-",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "396c7904",
      "metadata": {
        "id": "396c7904"
      },
      "source": [
        "<font color='green'>\n",
        "Here language model is represented by the object \"llm,\" which is being utilized to generate a completion or response based on a specific query.\n",
        "<br><br>\n",
        "The query, stored in the \"our_query\" variable is bieng passed to the model through llm object.\n",
        "<font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a2e267f6",
      "metadata": {
        "id": "a2e267f6",
        "outputId": "05d74fde-9976-4884-d1a3-7fc6e19dc4b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The currency of India is the Indian Rupee, symbolized as ₹ and abbreviated as INR.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "our_query = \"What is the currency of India?\"\n",
        "\n",
        "#Last week langchain has recommended to use invoke function for the below please :)\n",
        "get_completion(our_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2085724",
      "metadata": {
        "id": "e2085724"
      },
      "source": [
        "## Let's use open-source LLM hosted on Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "18ba8425",
      "metadata": {
        "id": "18ba8425"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HUGGINGFACEHUB_API_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9548eede",
      "metadata": {
        "id": "9548eede"
      },
      "outputs": [],
      "source": [
        "#from langchain.llms import HuggingFaceHub\n",
        "\n",
        "#The above have been updated recently, so going forward we have to use the below :)\n",
        "\n",
        "from langchain.llms import HuggingFaceEndpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "099a0220",
      "metadata": {
        "id": "099a0220",
        "outputId": "ddc6cee1-3c64-4aff-d8ff-624eb0ad8bec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-c40c38b7b054>:6: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
            "  llm = HuggingFaceEndpoint(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "#llm = HuggingFaceHub(repo_id = \"google/flan-t5-large\")\n",
        "\n",
        "#The above 'HuggingFaceHub' class has been depreciated, so please use the below class'HuggingFaceEndpoint'\n",
        "#and the below mentioned model outperforms most of the available open source LLMs\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\") # Model link : https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3beee630",
      "metadata": {
        "id": "3beee630"
      },
      "outputs": [],
      "source": [
        "# The LLM takes a prompt as an input and outputs a completion\n",
        "our_query = \"What is the currency of India?\"\n",
        "\n",
        "#Last week langchain has recommended to use invoke function for the below please :)\n",
        "completion = llm.invoke(our_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "259e2628",
      "metadata": {
        "id": "259e2628",
        "outputId": "b5afe2ff-0ac9-4602-b344-27e3b0ad227f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The currency of India is the Indian Rupee (INR). It is subdivided into 100 paise. The symbol for the Indian Rupee is ₹ and its ISO code is INR. The Reserve Bank of India issues and manages the currency.\n"
          ]
        }
      ],
      "source": [
        "print(completion)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}